










  1%|▎                                      | 10/1560 [00:35<1:16:45,  2.97s/it]










  1%|▌                                      | 20/1560 [01:16<2:00:12,  4.68s/it]










  2%|▊                                      | 30/1560 [02:02<1:55:46,  4.54s/it]









  2%|▉                                      | 39/1560 [02:37<1:43:25,  4.08s/it]










  3%|█▏                                     | 49/1560 [03:17<1:36:26,  3.83s/it]










  4%|█▍                                     | 59/1560 [04:03<2:01:09,  4.84s/it]










  4%|█▋                                     | 69/1560 [04:46<1:35:21,  3.84s/it]










  5%|█▉                                     | 79/1560 [05:23<1:20:06,  3.25s/it]










  6%|██▏                                    | 89/1560 [06:08<1:42:10,  4.17s/it]










  6%|██▍                                    | 99/1560 [06:43<1:27:57,  3.61s/it]
{'loss': 0.0174, 'learning_rate': 9.904906118270831e-06, 'epoch': 0.32}










  7%|██▋                                   | 109/1560 [07:22<1:34:08,  3.89s/it]










  8%|██▉                                   | 119/1560 [08:02<1:36:50,  4.03s/it]











  8%|███▏                                  | 130/1560 [08:43<1:30:10,  3.78s/it]









  9%|███▍                                  | 139/1560 [09:18<1:41:59,  4.31s/it]











 10%|███▋                                  | 150/1560 [10:00<1:37:38,  4.15s/it]









 10%|███▊                                  | 159/1560 [10:37<1:34:14,  4.04s/it]










 11%|████                                  | 169/1560 [11:11<1:25:24,  3.68s/it]










 11%|████▎                                 | 179/1560 [11:46<1:16:02,  3.30s/it]











 12%|████▋                                 | 190/1560 [12:28<1:25:21,  3.74s/it]









 13%|████▊                                 | 199/1560 [13:00<1:17:34,  3.42s/it]
{'loss': 0.0002, 'learning_rate': 9.611653577416508e-06, 'epoch': 0.64}











 13%|█████                                 | 210/1560 [13:38<1:11:17,  3.17s/it]









 14%|█████▎                                | 219/1560 [14:12<1:29:23,  4.00s/it]










 15%|█████▌                                | 229/1560 [14:49<1:27:37,  3.95s/it]










 15%|█████▊                                | 239/1560 [15:27<1:28:25,  4.02s/it]





 16%|█████▉                                | 244/1560 [15:48<1:25:53,  3.92s/it]Traceback (most recent call last):
  File "/home/xxm/下载/chatglm_project/ChatGLM-Efficient-Tuning/src/train_rm.py", line 95, in <module>
    main()
  File "/home/xxm/下载/chatglm_project/ChatGLM-Efficient-Tuning/src/train_rm.py", line 65, in main
    train_result = trainer.train()
  File "/home/xxm/anaconda3/envs/deepspeed/lib/python3.9/site-packages/transformers/trainer.py", line 1645, in train
    return inner_training_loop(
  File "/home/xxm/anaconda3/envs/deepspeed/lib/python3.9/site-packages/transformers/trainer.py", line 1938, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/xxm/anaconda3/envs/deepspeed/lib/python3.9/site-packages/transformers/trainer.py", line 2770, in training_step
    self.accelerator.backward(loss)
  File "/home/xxm/anaconda3/envs/deepspeed/lib/python3.9/site-packages/accelerate/accelerator.py", line 1819, in backward
    self.scaler.scale(loss).backward(**kwargs)
  File "/home/xxm/anaconda3/envs/deepspeed/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/xxm/anaconda3/envs/deepspeed/lib/python3.9/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
[31m╭───────────────────── [39m[1mTraceback (most recent call last)[31m[22m ──────────────────────╮
[31m│[39m /home/xxm/下载/chatglm_project/ChatGLM-Efficient-Tuning/src/[1mtrain_rm.py[22m:[94m95[39m   [31m│
[31m│[39m in [92m<module>[39m                                                                  [31m│
[31m│[39m                                                                              [31m│
[31m│[39m   92                                                                         [31m│
[31m│[39m   93                                                                         [31m│
[31m│[39m   94 [94mif[39m [91m__name__[39m == [33m"__main__"[39m:                                              [31m│
[31m│[39m [31m❱ [39m95 │   main()                                                              [31m│
[31m│[39m   96                                                                         [31m│
[31m│[39m                                                                              [31m│
[31m│[39m /home/xxm/下载/chatglm_project/ChatGLM-Efficient-Tuning/src/[1mtrain_rm.py[22m:[94m65[39m   [31m│
[31m│[39m in [92mmain[39m                                                                      [31m│
[31m│[39m                                                                              [31m│
[31m│[39m   62 │                                                                       [31m│
[31m│[39m   63 │   # Training                                                          [31m│
[31m│[39m   64 │   [94mif[39m training_args.do_train:                                          [31m│
[31m│[39m [31m❱ [39m65 │   │   train_result = trainer.train()                                  [31m│
[31m│[39m   66 │   │   trainer.log_metrics([33m"train"[39m, train_result.metrics)              [31m│
[31m│[39m   67 │   │   trainer.save_metrics([33m"train"[39m, train_result.metrics)             [31m│
[31m│[39m   68 │   │   trainer.save_state()                                            [31m│
[31m│[39m                                                                              [31m│
[31m│[39m /home/xxm/anaconda3/envs/deepspeed/lib/python3.9/site-packages/transformers/ [31m│
[31m│[39m [1mtrainer.py[22m:[94m1645[39m in [92mtrain[39m                                                     [31m│
[31m│[39m                                                                              [31m│
[31m│[39m   1642 │   │   inner_training_loop = find_executable_batch_size(             [31m│
[31m│[39m   1643 │   │   │   [96mself[39m._inner_training_loop, [96mself[39m._train_batch_size, args.a [31m│
[31m│[39m   1644 │   │   )                                                             [31m│
[31m│[39m [31m❱ [39m1645 │   │   [94mreturn[39m inner_training_loop(                                   [31m│
[31m│[39m   1646 │   │   │   args=args,                                                [31m│
[31m│[39m   1647 │   │   │   resume_from_checkpoint=resume_from_checkpoint,            [31m│
[31m│[39m   1648 │   │   │   trial=trial,                                              [31m│
[31m│[39m                                                                              [31m│
[31m│[39m /home/xxm/anaconda3/envs/deepspeed/lib/python3.9/site-packages/transformers/ [31m│
[31m│[39m [1mtrainer.py[22m:[94m1938[39m in [92m_inner_training_loop[39m                                      [31m│
[31m│[39m                                                                              [31m│
[31m│[39m   1935 │   │   │   │   │   [96mself[39m.control = [96mself[39m.callback_handler.on_step_begi [31m│
[31m│[39m   1936 │   │   │   │                                                         [31m│
[31m│[39m   1937 │   │   │   │   [94mwith[39m [96mself[39m.accelerator.accumulate(model):              [31m│
[31m│[39m [31m❱ [39m1938 │   │   │   │   │   tr_loss_step = [96mself[39m.training_step(model, inputs)  [31m│
[31m│[39m   1939 │   │   │   │                                                         [31m│
[31m│[39m   1940 │   │   │   │   [94mif[39m (                                                  [31m│
[31m│[39m   1941 │   │   │   │   │   args.logging_nan_inf_filter                       [31m│
[31m│[39m                                                                              [31m│
[31m│[39m /home/xxm/anaconda3/envs/deepspeed/lib/python3.9/site-packages/transformers/ [31m│
[31m│[39m [1mtrainer.py[22m:[94m2770[39m in [92mtraining_step[39m                                             [31m│
[31m│[39m                                                                              [31m│
[31m│[39m   2767 │   │   │   [94mwith[39m amp.scale_loss(loss, [96mself[39m.optimizer) [94mas[39m scaled_loss: [31m│
[31m│[39m   2768 │   │   │   │   scaled_loss.backward()                                [31m│
[31m│[39m   2769 │   │   [94melse[39m:                                                         [31m│
[31m│[39m [31m❱ [39m2770 │   │   │   [96mself[39m.accelerator.backward(loss)                           [31m│
[31m│[39m   2771 │   │                                                                 [31m│
[31m│[39m   2772 │   │   [94mreturn[39m loss.detach() / [96mself[39m.args.gradient_accumulation_steps  [31m│
[31m│[39m   2773                                                                       [31m│
[31m│[39m                                                                              [31m│
[31m│[39m /home/xxm/anaconda3/envs/deepspeed/lib/python3.9/site-packages/accelerate/[1mac[22m [31m│
[31m│[39m [1mcelerator.py[22m:[94m1819[39m in [92mbackward[39m                                                [31m│
[31m│[39m                                                                              [31m│
[31m│[39m   1816 │   │   [94melif[39m [96mself[39m.distributed_type == DistributedType.MEGATRON_LM:    [31m│
[31m│[39m   1817 │   │   │   [94mreturn[39m                                                    [31m│
[31m│[39m   1818 │   │   [94melif[39m [96mself[39m.scaler [95mis[39m [95mnot[39m [94mNone[39m:                                 [31m│
[31m│[39m [31m❱ [39m1819 │   │   │   [96mself[39m.scaler.scale(loss).backward(**kwargs)                [31m│
[31m│[39m   1820 │   │   [94melse[39m:                                                         [31m│
[31m│[39m   1821 │   │   │   loss.backward(**kwargs)                                   [31m│
[31m│[39m   1822                                                                       [31m│
[31m│[39m                                                                              [31m│
[31m│[39m /home/xxm/anaconda3/envs/deepspeed/lib/python3.9/site-packages/torch/[1m_tensor[22m [31m│
[31m│[39m [1m.py[22m:[94m487[39m in [92mbackward[39m                                                          [31m│
[31m│[39m                                                                              [31m│
[31m│[39m    484 │   │   │   │   create_graph=create_graph,                            [31m│
[31m│[39m    485 │   │   │   │   inputs=inputs,                                        [31m│
[31m│[39m    486 │   │   │   )                                                         [31m│
[31m│[39m [31m❱ [39m 487 │   │   torch.autograd.backward(                                      [31m│
[31m│[39m    488 │   │   │   [96mself[39m, gradient, retain_graph, create_graph, inputs=inputs [31m│
[31m│[39m    489 │   │   )                                                             [31m│
[31m│[39m    490                                                                       [31m│
[31m│[39m                                                                              [31m│
[31m│[39m /home/xxm/anaconda3/envs/deepspeed/lib/python3.9/site-packages/torch/autogra [31m│
[31m│[39m d/[1m__init__.py[22m:[94m200[39m in [92mbackward[39m                                                [31m│
[31m│[39m                                                                              [31m│
[31m│[39m   197 │   # The reason we repeat same the comment below is that              [31m│
[31m│[39m   198 │   # some Python versions print out the first line of a multi-line fu [31m│
[31m│[39m   199 │   # calls in the traceback and some print out the last line          [31m│
[31m│[39m [31m❱ [39m200 │   Variable._execution_engine.run_backward(  # Calls into the C++ eng [31m│
[31m│[39m   201 │   │   tensors, grad_tensors_, retain_graph, create_graph, inputs,    [31m│
[31m│[39m   202 │   │   allow_unreachable=[94mTrue[39m, accumulate_grad=[94mTrue[39m)  # Calls into th [31m│
[31m│[39m   203                                                                        [31m│
[31m╰──────────────────────────────────────────────────────────────────────────────╯
[1mKeyboardInterrupt